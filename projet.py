import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
import math
import pandas as pd

points =[(1,1),(1,2),(1,5),(3,4),(4,3),(6,2),(0,4)]
noms= ["M1", "M2", "M3", "M4", "M5", "M6", "M7"]


#########################################
#               Partie 1                #
#########################################

#S√©parer les coordonn√©es x et y
x = np.array([p[0] for p in points])
y = np.array([p[1] for p in points])


def afficher_stats(valeurs, noms):
    print("Moyenne :", np.mean(valeurs))
    print("M√©diane :", np.median(valeurs))
    print("Variance :", np.var(valeurs))
    print("Ecart-type :", np.std(valeurs))
    print("Minimum :", np.min(valeurs))
    print("Maximum :", np.max(valeurs))
    print("Etendue :", np.ptp(valeurs))


afficher_stats(x, "x")
afficher_stats(y, "y")

plt.scatter(x, y, color='blue')
for i in range(len(points)):
    plt.text(x[i] + 0.1, y[i] + 0.1, noms[i])
plt.title("Nuage de points")
plt.xlabel("x")
plt.ylabel("y")
plt.grid()
plt.show()

#   Interpr√©tation statistique :

#Les valeurs xx sont plus dispers√©es que les valeurs yy.
#La moyenne de xx est plus faible que celle de yy, indiquant une asym√©trie spatiale.
#L‚Äô√©tendue plus grande pour xx traduit une plus grande variabilit√© sur l‚Äôaxe horizontal.

#   Interpr√©tation graphique :

#Le nuage montre une certaine tendance croissante mais non strictement lin√©aire.
#Il est possible qu‚Äôune relation lin√©aire approximative existe entre xx et yy, √† tester dans la partie suivante.


#########################################
#               Partie 2                #
#########################################

# 2.1 Calcul des Coefficients de R√©gression

# Moyennes
x_moy = np.mean(x)
y_moy = np.mean(y)

# Coefficients
b1 = np.sum((x - x_moy) * (y - y_moy)) / np.sum((x - x_moy)**2)
b0 = y_moy - b1 * x_moy

print("bo =", b0)
print("b1 =", b1)

# Mod√®le de pr√©dictions
y_pred = b0 + b1 * x


# 2.3 Coefficient de D√©termination R¬≤

# R¬≤
SCE = np.sum((y - y_pred) ** 2)
SCT = np.sum((y - y_moy) ** 2)
SCR = np.sum((y_pred - y_moy) ** 2)
R2 = 1 - SCE / SCT
print("R¬≤ (Coefficient de d√©termination) :", R2)


# 2.2 Visualisation de la Droite de R√©gression

# Affichage
plt.scatter(x, y, label='Points')
plt.plot(x, y_pred, color='red', label=f'Droite de r√©gression: y = {b0:.2f} + {b1:.2f}x')
plt.legend()
plt.title(f'Droite de r√©gression lin√©aire simple (R¬≤ = {R2:.2f})')
plt.xlabel("x")
plt.ylabel("y")
plt.grid(True)
plt.show()
plt.savefig("figure_2_1.jpg")
print("Graphique enregistr√© dans le fichier figure_2_1.jpg")


#########################################
#               Partie 3                #
#########################################

#1. R√©sidus et somme des carr√©s des erreurs (SCE)
e = y - y_pred

SCE=0

for i in range(len(points)):
    SCE += e[i]**2 
print("SCE (Somme des carr√©s des erreurs) :", SCE)

#2. Etimation de la variance des erreurs : MSE
n= len(x)

MSE = SCE / (n-2)

print("MSE (Erreur quadratique moyenne) :", MSE)

#Le n-2 vient du fait qu'on a estim√© 2 param√®tres (b0 et b1). On parle alors de degr√©s de libert√©.

#3. Ecart-type des erreurs
s = np.sqrt(MSE)

print("√âcart-type des erreurs :", s)

#4. Interpr√©tation des R√©sultats

# üîπ Interpr√©tation des coefficients

#     b0=3.33 (ordonn√©e √† l'origine) : c'est la valeur estim√©e de y quand x=0. Cela signifie qu'√† l'origine de l'axe x, la droite de r√©gression pr√©voit y=3.33.

#     b1=‚àí0.15 (pente) : chaque augmentation de 1 unit√© en x entra√Æne une baisse moyenne de y de 0.15. La relation est donc l√©g√®rement d√©croissante, mais tr√®s faible.

# üîπ Coefficient de d√©termination R2

#     Le R2=0.049 (soit 4.9%) indique que seulement 4.9% de la variation de y est expliqu√©e par la variable x.

#     Cela signifie que la droite de r√©gression explique tr√®s peu la variabilit√© des points. La majorit√© de la variation de y provient donc d'autres facteurs non captur√©s par ce mod√®le.

# üîπ Analyse des erreurs

#     SCE (Somme des carr√©s des erreurs) : 11.42
#     ‚Üí mesure l‚Äôerreur globale du mod√®le (plus elle est faible, meilleur est l‚Äôajustement).

#     MSE (Erreur quadratique moyenne) : 2.28
#     ‚Üí estimation de la variance des erreurs r√©siduelles.

#     √âcart-type des erreurs : 1.51
#     ‚Üí en moyenne, les pr√©dictions du mod√®le s‚Äô√©cartent de 1.51 unit√©s des valeurs r√©elles.

#     Compar√© √† l‚Äô√©cart-type total de y qui est de 1.31, cela montre que la droite n'am√©liore pas vraiment la pr√©diction par rapport √† une moyenne constante.

#########################################
#               Partie 4                #
#########################################

# 4.1 Estimation de la variance des erreurs

# 4.2 Erreurs Standards des Coefficients

# Erreur standard de la pente
somme_x=0
for i in range(len(points)):
    somme_x += (x[i]-x_moy)**2

SEb1 = s/np.sqrt(somme_x)
print("Erreur standard de la pente:", SEb1)

# Erreur standard de l'ordonn√©e √† l'origine
SEb0 = s*np.sqrt(1/n+x_moy**2/somme_x)
print("Erreur standard de l'ordonn√©e √† l'origine", SEb0)

# 4.3 Test d'Hypoth√®se pour la Pente (b1)

# Hypoth√®ses :
# H0 : b1 = 0 (pas de relation lin√©aire)
# H1 : b1 != 0 (relation lin√©aire significative)

# Statistique de test

t_b1 = (b1-0)/SEb1 # t suit une loi de Student donc on calcul la p-valeur pour savoir si on rejette l'hypoth√®se ou non
p_b1 = 2 * (1 - stats.t.cdf(abs(t_b1), df=n - 2))
print("valeur de test", t_b1)
print("p-valeur:", p_b1)
if(p_b1<0.05):
    print("p-valeur<0,05 donc on rejette l'hypoth√®se, b1 est significatif")
else:
    print("p-valeur>0,05 donc on ne rejette pas l'hypoth√®se, il n'y a pas de preuve de relation lin√©aire")
    

# 4.4 Test d'Hypoth√®se pour l'Ordonn√©e √† l'Origine (b0)
# Hypoth√®ses : H0 : b0 = 0 vs H1 : b0 != 0

# Statistique de test

t_b0 = (b0-0)/SEb0
p_b0 = 2 * (1 - stats.t.cdf(abs(t_b0), df=n - 2))
print("valeur de test", t_b0)
print("p-valeur:", p_b0)
if(p_b0<0.05):
    print("p-valeur<0,05 donc on rejette l'hypoth√®se, b0 est significatif")
else:
    print("p-valeur>0,05 donc on ne rejette pas l'hypoth√®se, il n'y a pas de preuve de relation lin√©aire")

# 4.5 Intervalles de Confiance pour les Coefficients

alpha = 0.05

t_crit = stats.t.cdf(1-alpha/2, df= n-2)

IC_b1=[float(b1-t_crit*SEb1),float(b1+t_crit*SEb1)]
IC_b0=[float(b0-t_crit*SEb0),float(b0+t_crit*SEb0)]

print("Intervalle de confiance √† 95% pour b1:", IC_b1)
print("Intervalle de confiance √† 95% pour b0:", IC_b0)

# 4.6 Interpr√©tation des Tests Statistiques


#########################################
#               Partie 5                #
#########################################

# Classification Ascendante Hi√©rarchique (CAH)

# 1.a
def dist(p1, p2):
    """Distance euclidienne"""
    distance = math.sqrt((p1[0]-p2[0])**2 + (p1[1]-p2[1])**2)
    print("La distance euclidienne vaut : ", distance)
    return distance

# 1.b
def dist1(p1, p2):
    """Distance de Manhattan"""
    distance = abs(p1[0]-p2[0]) + abs(p1[1]-p2[1])
    print("La distance de Manhattan vaut : ", distance)
    return distance

# 1.c
def dist_inf(p1, p2):
    """Distance de Chebyshev (max)"""
    distance = max(abs(p1[0]-p2[0]), abs(p1[1]-p2[1]))
    print("La distance de Chebyshev vaut : ", distance)
    return distance

# 1.d : Distance de Ward ???


# 2.
def dist_min(tableau, dist_func):
    min_d = float('inf')
    couple_points = None
    for i in range(len(tableau)):
        for j in range(i+1, len(tableau)):
            d = dist_func(tableau[i], tableau[j])
            if d < min_d:
                min_d = d
                couple_points = (tableau[i], tableau[j])
    return couple_points, min_d


# 3.

# Trac√©
plt.scatter(x, y, color='blue')
for i in range(len(points)):
    plt.text(x[i] + 0.1, y[i] + 0.1, noms[i])
plt.title("Nuage de points")
plt.xlabel("x")
plt.ylabel("y")
plt.grid()
plt.show()

# Initialisation de la matrice
n = len(x)
matrice_1 = np.zeros((n, n))

# Remplissage de la matrice avec d¬≤
for i in range(n):
    for j in range(n):
        xi, yi = points[x[i]]
        xj, yj = points[x[j]]
        d_squared = (xi - xj)**2 + (yi - yj)**2
        matrice_1[i][j] = d_squared

# Affichage avec pandas pour lisibilit√©
data = pd.DataFrame(matrice_1, index=x, columns=x)
print("Matrice des distances euclidiennes au carr√© :\n")
print(data.round(1))


# Encadrer M1 et M7 (Classe Œì‚ÇÅ)
x_vals = [points["M1"][0], points["M7"][0]]
y_vals = [points["M1"][1], points["M7"][1]]
plt.plot(x_vals, y_vals, 'ro--')
plt.scatter(x_vals, y_vals, color='red')
plt.title("Regroupement initial : Classe Œì‚ÇÅ = {M1, M7}")
plt.grid(True)
plt.xlim(-1, 7)
plt.ylim(0, 6)
plt.show()

plt.savefig("figure_5_3.jpg")
print("Graphique enregistr√© dans le fichier figure_5_3.jpg")